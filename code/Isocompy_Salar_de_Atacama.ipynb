{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isocompy Salar de Atacama application\n",
    "\n",
    "We will explain an application of Isocompy in Salar de Atacama to clarify  the isocompy library usage on spatial and isotopic data to reach a group of models to estimate the spatio-temporal isotope values.\n",
    " \n",
    "Isocompy is designed to reach a general estimation model when there is heterogeneity in number of available data between variables, or when not all measurments are available for all the observed samples (stations). The goal is to obtain seasonal isotopic models to be able to predict the isotope values in given time and space.\n",
    "\n",
    "\n",
    "\n",
    "In this work, there is an acceptable amount of precipitation, relative humidity and temperature data in time ( the data doesn't have a good spatial variability), but  the isotopic observation data is limited and distributed in time intervals. More, the precipitation, relative humidity and temperature measurments are not available in the same time and/or space of the isotopic measurments.\n",
    "To reach a general estimation of seasonal isotopic values, we will model generate a group of independent models for each of the precipitation, relative humidity and temperature, based on the spatial data for desired months. **We will call this group of meteorological models, stage 1 models.**\n",
    "\n",
    "\n",
    "\n",
    "Then, because ther is not enough monthly data to have a meaningful isotopic monthly model, we will switch from monthly to seasonal models (in this case, a summer model for January, February and March): A seasonal isotopic model could contain isotope data from various month, integrated in a *season*. The precipitation, relative humidity and temperature values will be predicted in the coordination of isotopic measurments using stage 1 models, based on the date of isotopic observation date. Then the meteorological predicted values will be used to model isotopes. **We will call this group of meteorological models, stage 2 models.**\n",
    "\n",
    "This work could be seperated to the following main steps:\n",
    "\n",
    "1. Input data preparation and preprocessing\n",
    "\n",
    "\n",
    "2. Constructing the meteorological models (stage 1)\n",
    "\n",
    "\n",
    "3. Estimating the meteorological values based on the meteorological models in points where there is isotopic observations\n",
    "\n",
    "\n",
    "4. Constructing the isotopic models (stage 2)\n",
    "\n",
    "\n",
    "5. Predict the desired spatio-temporal isotope values, generating residual plots, meteoric lines plot and maps \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For more information about the example, refer to the [article]().\n",
    "\n",
    "The input data could be found in [github library]().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from isocompy.data_preparation import preprocess\n",
    "from isocompy.reg_model import model\n",
    "from isocompy.tools import session, evaluation, stats, plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "Input data have to be `Pandas Dataframe`.\n",
    "The fields ***ID***, ***Value*** and ***Date*** have to exist in each input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "dir_inp=r\"directory of the input data folder\"\n",
    "\n",
    "#Temperature data\n",
    "temp=pd.read_excel(join(dir_inp,\"temp_monthly.xls\"),sheet_name=\"temp_monthly\",header=0,index_col=False,keep_default_na=True)\n",
    "#relative humidity data\n",
    "hum=pd.read_excel(join(dir_inp,\"hum_monthly.xls\"),sheet_name=\"hum_monthly\",header=0,index_col=False,keep_default_na=True)\n",
    "#precipitation data\n",
    "rain=pd.read_excel(join(dir_inp,\"rain_monthly.xls\"),sheet_name=\"rain_monthly\",header=0,index_col=False,keep_default_na=True)\n",
    "\n",
    "#isotope data: They are not going to be used until stage 2 models.\n",
    "data_file_iso = join(dir_inp,\"Isotopes.xls\")\n",
    "iso_18 = pd.read_excel(data_file_iso,sheet_name=\"ISOT18O\",header=0,index_col=False,keep_default_na=True)\n",
    "iso_2h=pd.read_excel(data_file_iso,sheet_name=\"ISOT2H\",header=0,index_col=False,keep_default_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Input data preparation and preprocessing\n",
    "\n",
    "\n",
    "\n",
    "To prepare each group of the input data (meteorological (stage 1) models and isotope models (stage 2) ), we have to use `preprocess` class. This class allows us to integrate the data from daily or monthly format to average monthly. It is also possible to remove outliers using the existed methods.  In automatic outlier detection and removal and default values could be found in `help(preprocess.fit)`.\n",
    "\n",
    "\n",
    "`fields` parameter determines which columns (fields) of the dataframe have to be considered as independent variables to explain the dependent variable. The dependent variable measurments are in ***Value*** column of the dataframe. `var_name` determines the given name to the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data class\n",
    "ddir=r\"directory of the outputs data folder\"\n",
    "ddir_inp_classess=join(ddir,\"input_data_classess\")\n",
    "#Precipitation\n",
    "#Precipitation\n",
    "preped_prc=preprocess()\n",
    "preped_prc.fit(inp_var=rain,var_name=\"prc\",fields=[\"CooX\",\"CooY\",\"CooZ\"],remove_outliers=False,direc=ddir_inp_classess)\n",
    "\n",
    "#Temperature\n",
    "preped_tmp=preprocess()\n",
    "preped_tmp.fit(inp_var=temp,var_name=\"tmp\",fields=[\"CooX\",\"CooY\",\"CooZ\"],remove_outliers=False,direc=ddir_inp_classess)\n",
    "\n",
    "#Humidity\n",
    "preped_hmd=preprocess()\n",
    "preped_hmd.fit(inp_var=hum,var_name=\"hmd\",fields=[\"CooX\",\"CooY\",\"CooZ\"],remove_outliers=False,direc=ddir_inp_classess)\n",
    "\n",
    "#isotopes\n",
    "prep_st2_iso1=preprocess()\n",
    "prep_st2_iso1.fit(inp_var=iso_18,var_name=\"iso_18\",fields=[\"CooX\",\"CooY\",\"CooZ\"],remove_outliers=False,direc=ddir_inp_classess)\n",
    "\n",
    "prep_st2_iso2=preprocess()\n",
    "prep_st2_iso2.fit(inp_var=iso_2h,var_name=\"iso_2h\",fields=[\"CooX\",\"CooY\",\"CooZ\"],remove_outliers=False,direc=ddir_inp_classess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constructing the meteorological models (stage 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To construct a group of models, the `model` class object have to be used.\n",
    "`st1_fit` method creates the (stage 1) meteorological models. `var_cls_list` accepts a list of **preprocess** class objects that we want to model. Each `preprocess` class object will have it's own estimation model based on `preprocess` class determined input arguments. In other words, for each `preprocess` class, `model` class will constructs and stores models. `st1_model_month_list` is a list of months that determine for which months the models to be created. (There is a seperate model for each month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stage 1 model\n",
    "dir_outs_st1=join(ddir,\"st1_all_month\")\n",
    "est_class=model()\n",
    "est_class.st1_fit(var_cls_list=[preped_prc,preped_tmp,preped_hmd],\n",
    "                    st1_model_month_list=[1,2,3],\n",
    "                    direc=dir_outs_st1)\n",
    "\n",
    "#stage 1 model plots\n",
    "plots.best_estimator_plots(est_class,st2=False)\n",
    "plots.partial_dep_plots(est_class,st2=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimating the meteorological values based on the meteorological models in points where there is isotopic observations\n",
    "\n",
    "`st1_predict` is used to estimete the meteorological values using the stage 1 models that are already created. The predictions from `st1_predict` will be fed to the second stage models.\n",
    "\n",
    "\n",
    "To calculate stage 1 predictions, independent variables that are selected based on the statistical tests needed to be available. This means that the used independent features in st1 have to be available in each st2 `preprocess` class (in this case: *prep_st2_iso1* and *prep_st2_iso2* have to have *CooX, CooY, CooZ* fields).\n",
    "`cls_list` is a list of  `preprocess` classes that we want to have an independent model for each one of them in stage 2. (in this case: one model for *prep_st2_iso1* and another one for *prep_st2_iso2*)\n",
    "\n",
    "The `st2_model_month_list` identifies the *months* that form a *season* in stage 2. Just the data from that specific months will be selected and predicted. obviously, the months in `st2_model_month_list` have to exist in `st1_model_month_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage 1 prediction\n",
    "est_class.st1_predict(cls_list=[prep_st2_iso1,prep_st2_iso2],st2_model_month_list=[1,2,3])\n",
    "\n",
    "#save stage 1 model object\n",
    "est_class_dir=session.save(est_class,name='est_class_st1') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Constructing the isotopic models (stage 2)\n",
    "To construct the stage 2 models, the independent variables for each `preprocess` introduced class have to be determined in `st2_model_var_dict`. In this example, the independent variables for *is1* and *is2* are *CooX , CooY, CooZ, tmp, hmd, prc*. If `st2_model_var_dict` is None, all independent variables will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stage 2 model: The predicted features from st2 will be used:\n",
    "#determine the input and output of the second stage model:\n",
    "st2_model_var_dict={\"iso_18\":[\"CooX\",\"CooY\",\"CooZ\",\"tmp\",\"prc\",\"hmd\"],\"iso_2h\":[\"CooX\",\"CooY\",\"CooZ\",\"tmp\",\"prc\",\"hmd\"]}\n",
    "args_dic={\"feature_selection\":\"auto\",\"vif_threshold\":5, \"vif_selection_pairs\":[[\"CooZ\",\"tmp\"]], \"correlation_threshold\":0.87,\"vif_corr\":True,\"p_val\":0.05}\n",
    "\n",
    "est_class.st2_fit(model_var_dict=st2_model_var_dict,args_dic=args_dic)\n",
    "\n",
    "#save stage 2\n",
    "est_class_st2_dir=session.save(est_class,name='est_class_st2') \n",
    "\n",
    "#stage 2 model plots\n",
    "plots.best_estimator_plots(est_class,st1=False)\n",
    "plots.partial_dep_plots(est_class,st1=False) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Predict the desired spatio-temporal isotope values\n",
    "`evaluation` class is used to estimate values from stage 2 models (isotope models) and to evaluate the results. The estimations serves two perposes:\n",
    "\n",
    "\n",
    "1. To evaluate the predictions by comparing it with the real values, global and local meteorological lines and investigate residuals.\n",
    "    \n",
    "    `pred_inputs` determines the dataframe that is gonna be used for prediction and evaluation.  Using the `all_preds` dataframe from the `model` class (here, *est_class*) that contains all the predictions and choosing the needed variables that are needed for first stage models (here, *CooX, CooY, CooZ*) as `pred_inputs`, the `predict` function will estimate the stage 2 models (for *iso_18* and *iso_2h*). calling `isotopes_meteoline_plot` from `plots` class, creates the isotope meteoric line  and residuals plots. Note that to execute `isotopes_meteoline_plot` for evaluation correctly, the `pred_inputs` dataframe have to include *ID* and *month* fields (which by default is created already in `all_preds` dataframe). `obs_data` and `residplot` have to be set to `True` since the `pred_inputs` contains observed data and we desire to have the residuals plots.\n",
    "\n",
    "2. To generate predictions in desired spatio temporal scenarios (As an example, to make a map of the points in an specific month)\n",
    "\n",
    "    `pred_inputs` is the input dataframe that includes the needed variables that are needed for first stage models (here, *CooX, CooY, CooZ*). There is no need to *ID* and *month* fields since the points are not observation points. The `predict` function will estimate the stage 2 models (for *iso_18* and *iso_2h*). Calling `isotopes_meteoline_plot` from `plots` class, creates the isotope meteorological line plots, plotting all the estimations for `pred_inputs` points.\n",
    "\n",
    "It is possible to generate the maps of the area in each month for desired features using `map_generator` method. The *ev_class_map* which is the evaluation class containing the predictions in desired points, identifies the points that will be included in the generated maps. By identifing a shape file, it is possible to add a background shape file to the .png maps. Defining the *observed_class_list* will result in showing the points that the data are measured on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_outs=r\"directory\"\n",
    "\n",
    "#to predict in points of observed data:\n",
    "#determine the points with needed features (from the model class)\n",
    "pred_inputs=est_class.all_preds[[\"CooX\",\"CooY\",\"CooZ\",\"month\",\"ID\"]].reset_index()\n",
    "\n",
    "ev_class_obs=evaluation()\n",
    "ev_class_obs.predict(est_class,pred_inputs=pred_inputs,direc=join(dir_outs,\"preds_obs\"))\n",
    "\n",
    "#to compare 2 isotopes, resodual plots and meteoric lines :                     \n",
    "plots.isotopes_meteoline_plot(ev_class_obs,est_class,iso_18=iso_18,iso_2h=iso_2h,var_list=['iso_18','iso_2h'],obs_data=True,residplot=True)\n",
    "       \n",
    "                     \n",
    "#to predict in points to generate maps: (no observations)\n",
    "#read points:\n",
    "data_file = join(dir_inp,\"x_y_z.xls\")\n",
    "pred_inputs_map=pd.read_excel(data_file,sheet_name=\"x_y_z\",header=0,index_col=False,keep_default_na=True)\n",
    "                     \n",
    "ev_class_map=evaluation()\n",
    "ev_class_map.predict(est_class,pred_inputs=pred_inputs_map,direc=join(dir_outs,\"preds_map\"))\n",
    "#to compare 2 isotopes and meteoric lines:       \n",
    "plots.isotopes_meteoline_plot(ev_class_map,est_class,var_list=['iso_18','iso_2h'])\n",
    "\n",
    "# To generate the maps\n",
    "\n",
    "opt_title_list=[\"Precipitation (mm)\",\"Relative Humidity (%)\", \"Temperature ($^\\circ$C)\", f'\\N{GREEK SMALL LETTER DELTA}\\N{SUPERSCRIPT ONE}\\N{SUPERSCRIPT EIGHT}O'+'(\\u2030 VSMOW)']\n",
    "feat_list=[\"prc\",\"hmd\",\"tmp\",\"iso_18\"]\n",
    "observed_class_list=[preped_prc,preped_hmd,preped_tmp,prep_st2_iso1]\n",
    "\n",
    "# to create .pngs with a shape file and an HTML interactive map\n",
    "shp_file=r\"directory of the shape files\"\n",
    "plots.map_generator(ev_class=ev_class_map,feat_list=feat_list,observed_class_list=observed_class_list,shp_file=shp_file,opt_title_list=opt_title_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of some capabilities of Isocompy classes amd methods\n",
    "\n",
    "The time window could be from monthly average of each year to monthly average of all years. In the former, just the inputs have to be for an specific year\n",
    "ability to report model uncertainty\n",
    "\n",
    "## preprocess.fit\n",
    "\n",
    "* daily or monthly data\n",
    "* possibility to determine el nino, la nina or all year\n",
    "* possibility to remove outliers based on quartiles or IQR formula. Sure it also can be done manually in the dataframe, then set \"remove_outliers\" to False\n",
    "* Generate reports of data integration in each step\n",
    "* Removing outliers could be done not considering the zero values in the database. (The zero values will be seperated, outliers will be removed, then zero values will be added to database)\n",
    "* Data averaging method. available options are arithmetic  or geometric\n",
    "* ability to define brute-force searching hyperparameters\n",
    "\n",
    "## model.st1_fit\n",
    "\n",
    "* Manual or auto feature selection. If auto: ability to determine p_value, VIF, VIF - correlation analysis and determining the possible pairs to remove if multicolinearity and correlation exists\n",
    "\n",
    "## plots.best_estimator_plots\n",
    "\n",
    "ability to plot and report the model fit and model uncertainty\n",
    "\n",
    "## plots.partial_dep_plots\n",
    "\n",
    "ability to plot partial dependency plots\n",
    "\n",
    "\n",
    "## est_class.st1_predict\n",
    "* first stage models integration\n",
    "* the ability to limit the desired month\n",
    "\n",
    "## model.st2_fit\n",
    "* ability to select the best models based on the isotopic lines such as global or local.\n",
    "* ability to select the best models based on various custom error functions.\n",
    "* Manual or auto feature selection. If auto: ability to determine p_value, VIF, VIF - correlation analysis and determining the possible pairs to remove if multicolinearity and correlation exists\n",
    "\n",
    "## plots.isotopes_meteoline_plot\n",
    "* plots and reports the observes vs calculated or the new points against isotopic lines, calculating residuals and goodness of fits.\n",
    "\n",
    "**all_preds** dataframe in evaluation class contains the predicted data from the first stage"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e467dfb405db84710bbd3bec33aa6227c22fb8dbfe5137828c095f91c1f66026"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('pysplitenv': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
